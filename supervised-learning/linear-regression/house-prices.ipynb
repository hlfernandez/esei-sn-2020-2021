{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal utilizando `sklearn`: predicción de precios de casas\n",
    "\n",
    "En este notebook vamos a calcular modelos de regresión lineal para predecir los precios de casas utilizando este dataset disponible en Kaggle: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/.\n",
    "\n",
    "En primer lugar, cargamos las librerías `numpy` y `pandas` y listamos los ficheros que tenemos en el directorio actual para comprobar que tenemos los ficheros de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de entrenamiento (`train.csv`) y también los datos de test que trae el dataset (`test.csv`). Los datos de test no tienen la variable que queremos predecir (`SalePrice`) ya que se trata  de un dataset para una competición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "print(\"Train size: \", train.shape)\n",
    "print(\"Test size: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos las primeras filas de cada dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.head())\n",
    "print('**'* 50)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos información básica acerca de cada dataset utilizando las funciones `info()` y `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())\n",
    "print('**'* 50)\n",
    "print(train.describe())\n",
    "print('**'* 50)\n",
    "print(test.info())\n",
    "print('**'* 50)\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repasa la descripción del dataset en Kaggle (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) para entender qué información nos ofrece cada columna.                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos\n",
    "\n",
    "La variable que queremos predecir es el precio de venta, que se encuentra en la columna `SalePrice`. Utilizamos la función `displot` (https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot) de la librería seaborn para visualizar la distribución de esta variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['SalePrice'].describe())\n",
    "\n",
    "sns.displot(train['SalePrice'], kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes explorar otras variables numéricas del dataset utilizando la misma representación.\n",
    "\n",
    "Otra visualización útil de este tipo de datos es crear un mapa de calor para visualizar la correlación entre todas las las variables numéricas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "sns.heatmap(train.corr(), cmap='coolwarm', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza esta tabla, fijándote especialmente en la última fila (o columna) donde se pueden ver las correlaciones con la variable que queremos predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de datos\n",
    "\n",
    "### Selección de variables predictoras\n",
    "\n",
    "Para reducir la cantidad de variables, vamos a quedarnos con aquellas que más correlación tienen con la variable que queremos predecir. Este valor se define en la variable `correlation_threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_threshold = 0.35\n",
    "\n",
    "corr = train.corr()\n",
    "\n",
    "columns = corr[corr['SalePrice'] > correlation_threshold].index\n",
    "\n",
    "print(columns)\n",
    "\n",
    "train.filtered = train[columns]\n",
    "\n",
    "print(\"Train size: \", train.filtered.shape)\n",
    "\n",
    "print(train.filtered.head())\n",
    "\n",
    "test.filtered = test[columns.drop('SalePrice')]\n",
    "\n",
    "print(\"Test size: \", test.filtered.shape)\n",
    "\n",
    "print(test.filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de las variables seleccionadas\n",
    "\n",
    "Podemos visualizar la relación entre cada variable seleccionada y el precio de venta utilizando gráficos de dispersión (o *scatter plots*). Por ejemplo, el siguiente gráfico muestra la relación con `LotFrontage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x='LotFrontage', y='SalePrice', data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería seaborn incluye una función llamada `lmplot` para visualizar un modelo de regresión simple entre dos variables (https://seaborn.pydata.org/generated/seaborn.lmplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='LotFrontage', y='SalePrice', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas variables, en lugar de un rango contunuo muy amplio, se limitan a unos pocos valores. Este es el caso de `GarageCars`, que podemos visualizar utilizando la función `boxplot` de seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.boxplot(x='GarageCars',y='SalePrice',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza el resto de variables utilizando el tipo de gráfico más adecuado (puedes probar los dos y comprobar el resultado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores perdidos\n",
    "\n",
    "Vamos a analizar si existen filas con missing data en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train.filtered.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podríamos:\n",
    "- Eliminar las filas con valores perdidos.\n",
    "- Utilizar alguna estrategia para imputar valores perdidos y poder utilizar todas las filas.\n",
    "\n",
    "#### Eliminar filas con valores perdidos\n",
    "\n",
    "Aplicando esta estrategia, simplemente eliminamos las columnas con algún valor perdido utilizando la función `dropna` (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.filtered.clean = train.filtered.dropna()\n",
    "\n",
    "total = train.filtered.clean.isnull().sum().sort_values(ascending=False)\n",
    "print(total)\n",
    "\n",
    "print(train.filtered.clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputar valores perdidos\n",
    "\n",
    "Al eliminar filas con valores perdidos reducimos el tamaño del dataset de entrenamiento a 1121 muestras, por lo que puede que estemos perdiendo información útil y valiosa. Para evitar esta pérdida, se pueden aplicar técnicas de imputación de valores perdidos. Básicamente, estas filas consisten en asignar el mismo valor a todos los valores perdidos para una variable (p. ej.: asignar el valor medio). Esta página de sklearn ofrece más información: https://scikit-learn.org/stable/modules/impute.html\n",
    "        \n",
    "Vamos a utilizar la clase `SimpleImputer` (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) para realizar este proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "impute_missing=SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "impute_missing.fit(train.filtered)\n",
    "\n",
    "train.filtered.clean = impute_missing.transform(train.filtered)\n",
    "\n",
    "train.filtered.clean = pd.DataFrame(data=train.filtered.clean,columns=train.filtered.columns)\n",
    "\n",
    "total = train.filtered.clean.isnull().sum().sort_values(ascending=False)\n",
    "print(total)\n",
    "\n",
    "print(train.filtered.clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualización de la correlación y filtrado final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos limpiado el dataset, podemos calcular de nuevo la correlación con la variable de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "sns.heatmap(train.filtered.clean.corr(), cmap='coolwarm', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mejorar la visualización anterior de dos maneras: ordenando las variables de mayor a menor correlación con la variable objetivo y cogiendo el subconjunto de `k` variables predictoras con más correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # number of variables for heatmap\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "corrmat = train.filtered.clean.corr()\n",
    "\n",
    "top_cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train.filtered.clean[top_cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, \n",
    "    cbar=True, annot=True, square=True, \n",
    "    fmt='.2f', annot_kws={'size': 10},\n",
    "    yticklabels=top_cols.values, xticklabels=top_cols.values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos filtrar nuevamente los conjuntos de train y test utilizando estas `top_cols`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = top_cols\n",
    "\n",
    "print(columns)\n",
    "\n",
    "train.final = train.filtered.clean[top_cols]\n",
    "\n",
    "print(\"Train size: \", train.final.shape)\n",
    "\n",
    "print(train.final.head())\n",
    "\n",
    "train.isnull().sum().sort_values(ascending=False).head(20)\n",
    "\n",
    "test.final = test[columns.drop('SalePrice')]\n",
    "\n",
    "print(\"Test size: \", test.final.shape)\n",
    "\n",
    "print(test.final.head())\n",
    "\n",
    "test.final.isnull().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### División en Train y Validation\n",
    "\n",
    "Utilizaremos una validación *holdout*, por lo que dividimos el dataset de entrenamiento en dos subcojuntos: 80% de datos para `train` y 20% `validation` (el porcentaje de datos para test se especifica en la variable `test_size`). Observa cómo esta función devuelve 4 subconjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.final.drop('SalePrice', axis=1),\n",
    "    train.final['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=2020\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Empezaremos probando el modelo `LinearRegression` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Importamos el modelo que queremos utilizar e invocamos a la función `fit` para ajustar el modelo. Este método se utiliza para entrenar cualquier modelo en sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Podemos imprimir los pesos de la ecuación de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar predicciones para el conjunto de validación\n",
    "\n",
    "Utilizamos el modelo ajustado para realizar predicciones para el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_val)\n",
    "predictions= predictions.reshape(-1,1)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos las predicciones con los valores reales (disponibles en la variable `y_val`). Si las predicciones fuesen perfectas obtendríamos una linea recta, pero como es esperable hay cierto margen de error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(y_val, predictions)\n",
    "plt.xlabel('Y Val')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de las predicciones\n",
    "\n",
    "El paquete `sklearn.metrics` ofrece diferentes métricas para la evaluación de los modelos de clasificación y regresión. En este caso, aplicaremos tres métricas específicas para problemas de regresión:\n",
    "- Mean Absolute Error (https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error).\n",
    "- Mean Squared Error (https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error).\n",
    "- Root Mean Squared Error.\n",
    "- R^2 score o coeficiente de determinación (https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, predictions)))\n",
    "print('R^2:', metrics.r2_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de datos\n",
    "\n",
    "Como ya hemos visto, en algunos algoritmos (basados en distancias) es necesario escalar los datos de entrada para evitar que ciertas variables dominen el entrenamiento. En el caso de la regresión lineal no es necesario, aunque hay quien prefiere hacerlo.\n",
    "\n",
    "A la hora de ajustar algunos modelos mediante técnicas de optimización, el hecho de que ciertas variables tengan otra escala pueden hacer que sea más costoso encontrar la solución ópima.\n",
    "\n",
    "En este apartado veremos cómo escalar datos utilizando la clase `StandardScaler` de skearn (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) y volveremos a calcular la regresión lineal.\n",
    "\n",
    "En primer lugar, importamos la clase y ajustamos el escalador utilizando solo los datos de la partición entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este objeto `scale` ajustado lo utilizaremos a continuación para escalar tanto la propia partición de entrenamiento como la partición de validación. Esto debe hacerse así para no traspasar información (indirectamente) del conjunto de validación al ajuste del modelo, algo que pasaría si creásemos el objeto de escalado utilizando el conjunto completo de datos de train.\n",
    "\n",
    "Comenzamos por la partición de entrenamiento, la escalamos y la comparamos con la original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.scaled = scale.transform(X_train)\n",
    "X_train.scaled = pd.DataFrame(data=X_train.scaled, columns=X_train.columns)\n",
    "\n",
    "print(X_train.describe())\n",
    "print(X_train.scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y escalamos del mismo modo la partición de validación. Al entrenar el modelo con datos escalado, significa que debemos escalar también los datos de validación y de test. En un caso real, si tuviésemos el modelo ajustado y quisésemos clasificar una muestra nueva, tendríamos que escalar esta antes de aplicarle el modelo (utilizando el escalado calculado con los datos con los que ajustamos el modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.scaled = scale.transform(X_val)\n",
    "X_val.scaled = pd.DataFrame(data=X_val.scaled, columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente, repetimos el proceso anterior para ajustar el modelo, realizar las predicciones y calcular las métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train.scaled, y_train)\n",
    "print(lm)\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)\n",
    "\n",
    "predictions = lm.predict(X_val.scaled)\n",
    "predictions= predictions.reshape(-1,1)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(y_val, predictions)\n",
    "plt.xlabel('Y Val')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.show()\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, predictions)))\n",
    "print('R^2:', metrics.r2_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Observas diferencias en los coeficientes de la ecuación y/o en los resultados de las métricas de evaluación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios propuestos\n",
    "\n",
    "Al acabar el Notebook, puedes continuar trabajando con estos ejercicios:\n",
    "- La librería sklearn incluye más modelos de regresión como `DecisionTreeRegressor`, `GradientBoostingRegressor`, o `RandomForestRegressor`. Prueba estos (y otros que quieras) y compara los resultados.\n",
    "- Si ejecutaste el notebook de forma lineal, habrás calculado la regresión con el dataset con valores perdidos inputados. Prueba la estrategia alternativa de eliminar las filas que los contengan y compara los resultados.\n",
    "- En este repositorio (https://github.com/mattnedrich/GradientDescentExample) hay un ejemplo de cálculo de regresión lineal mediante *gradient descent*, desarrollado en esta página: https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/ Echa un vistazo a la entrada de blog y, si tienes ganas y tiempo, programa el código y comprueba cómo funciona el algoritmo en un dataset sencillo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
